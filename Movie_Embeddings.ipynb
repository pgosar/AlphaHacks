{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Embeddings",
      "provenance": [],
      "authorship_tag": "ABX9TyNkBDBVcZ4uWsrwCqTPZ9DU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgosar/AlphaHacks/blob/main/Movie_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk67vTkTen_v"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXb6l5XTgUgA",
        "outputId": "ce5bfba5-f2f1-4cc9-f3db-f6d8b7101617"
      },
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "os.listdir(dataset_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README', 'imdbEr.txt', 'train', 'imdb.vocab', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmz4emhlhD66",
        "outputId": "9b6199be-5e48-4d3b-985b-a959f3ca0a04"
      },
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsup',\n",
              " 'unsupBow.feat',\n",
              " 'urls_neg.txt',\n",
              " 'urls_pos.txt',\n",
              " 'urls_unsup.txt',\n",
              " 'neg',\n",
              " 'labeledBow.feat',\n",
              " 'pos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIIdFLurUZLY"
      },
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NqOwcvmUjum",
        "outputId": "de9a1838-c94f-465e-af75-3f4c170a1853"
      },
      "source": [
        "batch_size = 1024\n",
        "seed = 123\n",
        "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
        "    subset='training', seed=seed)\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
        "    subset='validation', seed=seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBVTKKiDU2Uc",
        "outputId": "f55ff17e-8b61-4fa3-d3f7-54f006569ea1"
      },
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 b'It\\'s always nice to see Angela Bassett getting to do a role that she can really sink her teeth into. She is at times intense, funny and even sexy in her role as Lena, a \"colored\" woman forced to make a home on a desolate mudbank just outside of Cape Town, South Africa. Danny Glover is also good in a not entirely sympathetic role as her partner, Boesman. Willie Jonah gives a finely nuanced performance as the stranger that discovers Boesman and Lena\\'s new living area. It\\'s not often that you get a chance to see an intelligent film dealing with mature themes. Although it is based on a play, the late director John Berry (who also directed Claudine) opens the material up by having the film shot in the widescreen Cinemascope format. He also keeps things visually interesting through the creative blocking of actors and by showing us things only mentioned in the play. Just like Diahann Carroll in Claudine, John Berry may have directed Angela Bassett into an Academy Award nomination. This is definitely a film worth searching for.'\n",
            "0 b'This is the biggest piece of lamo I\\'ve ever watched. It is excruciatingly boring I would have rather sat through a seminar on creationism than have watched this if i had known it was going to be as boring as it was. Not even the 40 seconds of the hot chick in the bikini with the big ta tas redeems this of anything lower than a 1.<br /><br />The reviews of this movie claiming that this movie is \"unintentionally funny\" are absurd and just plain WRONG. Not one thing is funny about this movie. they spend the first 50 or so minutes walking through the woods talking about stuff you wouldn\\'t understand nor care about and it is just as lame when the people start dying because you don\\'t even know who the people are because they are so UNINTERESTING. Honestly though, I didn\\'t watch it to the ending, but that should say something about how horrible it is. WORST MOVIE EVER.<br /><br />Immediately after ejecting this filth from my DVD player I started scraping it against the cement in front of my house, not wanting other blockbuster customers to have to fall upon the same mistake i had made as to rent this movie. Then Zach peed his pants. Thankyou for your time.'\n",
            "0 b\"Wow, what a snoozer. Definately one of bacon's worst films. The bad acting coupled with a formulatic, if not incredulous, script make me yearn for time I wasted on viewing this on cable television back. Not really much I can say about it, a basketball scout gets too attached to the person he's recruiting, who happens to belong to a tribe that happens to be on the verge of war which happens to be decided by (spoiler) a basketball game. Grade: F+\"\n",
            "0 b'I don\\'t think you can get much worse then this. Put together bad actors, fake limbs, and three stupid stories and what do you get? This B-rate pointless excuse for a movie.<br /><br />The first story immediately shows the bad video quality and the acting is just really pathetic, especially when you bring in the 25 year old posing as a grandma with the usually grandma bun over the ears bit. Plus, the man is OK, but the woman is rather ugly. \"You look great!\" NOT! The werewolf in this one was the best one out of all three I\\'d say, but its still not impressive since it was all bad costume. The face on the woman later was decent enough for halloween but not for a werewolf movie.<br /><br />The more stories you go through the worse it gets. There are two lesbians in this next one who are completely retarded its ridiculous. The whole \"I want to be a werewolf, too\" \"How could you do this to me?!\" Was silly to say. You asked for it now get over it! The werewolf will not even be spoken of...its a rat!<br /><br />The third one has no point...almost forty five minutes of running and boring narration make up this story and the whole switch thing still didn\\'t make it interesting. Boring!<br /><br />Music, Yes, bad...who couldn\\'t even hear some parts it was stupid. Animals effects were either rat or pig-like which was stupid. They couldn\\'t use lion sounds? Guess not, GOOD movies use that. Well, i =f you enjoy B-rates this is good for you. I got this movie since I\\'m a hardcore werewolf fan and i\\'ll buy ANY werewolf movie and watch it more then once, but thats just me. If you prefer Good ones, don\\'t waste your money. I beg YOU!'\n",
            "0 b\"i didn't enjoy this movie at all.for one,i just found it crude and vulgar,for no reason.i also felt it's misogynistic(against women.)also,the movie really doesn't appear to be about anything,and i didn't find any of the characters likable.really,the there doesn't seem to be any point to it all.maybe i'm missing something,but for me,this movie is pretty much a waste of time,when i could have been doing something more productive and enjoyable.like using my face as a pin cushion.James garner is in this thing,as are C.Thomas Howell and Shirley Jones,and James Cromwell.all are wasted here,and i'm sure this was a low point in each of their respective careers.Jennilee Harrison(from the later years of Three's Company)is also in the movie,and it is nice to see her in a non ditsy role.but other than that,she can't rise above the mediocre script.for me,Tank is a 3/10\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q20dBNJgaGN2"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L8rAjaFauWe",
        "outputId": "ff2d88ab-9388-4171-a0d0-2f40fa041396"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)\n",
        "\n",
        "result = embedding_layer(tf.constant([1,2,3]))\n",
        "result.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00973222, -0.01957756,  0.04395263,  0.0133597 , -0.01553816],\n",
              "       [-0.00042682,  0.02788993, -0.01582443, -0.00634535, -0.02841049],\n",
              "       [ 0.03374845, -0.04762805,  0.00262735, -0.03352543,  0.01539638]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctpwihTxbTD9"
      },
      "source": [
        "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "\n",
        "# Vocabulary size and number of words in a sequence.\n",
        "vocab_size = 10000\n",
        "sequence_length = 100\n",
        "\n",
        "# Use the text vectorization layer to normalize, split, and map strings to\n",
        "# integers. Note that the layer uses the custom standardization defined above.\n",
        "# Set maximum_sequence length as all samples are not of the same length.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_ds = train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsVkbksfo_2z"
      },
      "source": [
        "embedding_dim=16\n",
        "\n",
        "model = Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tdlpRurqeZd"
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUNC6Gzqqie5"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw93I91iqkh_",
        "outputId": "e6e2cedc-4876-4a62-a085-ff9719fdf0c3"
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=15,\n",
        "    callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 4s 151ms/step - loss: 0.6921 - accuracy: 0.5028 - val_loss: 0.6906 - val_accuracy: 0.4886\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.6884 - accuracy: 0.5028 - val_loss: 0.6857 - val_accuracy: 0.4886\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.6820 - accuracy: 0.5028 - val_loss: 0.6777 - val_accuracy: 0.4886\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.6701 - accuracy: 0.5028 - val_loss: 0.6624 - val_accuracy: 0.4886\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.6506 - accuracy: 0.5028 - val_loss: 0.6410 - val_accuracy: 0.4886\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.6249 - accuracy: 0.5155 - val_loss: 0.6151 - val_accuracy: 0.5332\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.5941 - accuracy: 0.5900 - val_loss: 0.5858 - val_accuracy: 0.6056\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 2s 87ms/step - loss: 0.5601 - accuracy: 0.6650 - val_loss: 0.5550 - val_accuracy: 0.6598\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 2s 87ms/step - loss: 0.5243 - accuracy: 0.7246 - val_loss: 0.5249 - val_accuracy: 0.6992\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.4897 - accuracy: 0.7596 - val_loss: 0.4976 - val_accuracy: 0.7314\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.4580 - accuracy: 0.7860 - val_loss: 0.4741 - val_accuracy: 0.7500\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 2s 88ms/step - loss: 0.4298 - accuracy: 0.8046 - val_loss: 0.4545 - val_accuracy: 0.7618\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 2s 87ms/step - loss: 0.4051 - accuracy: 0.8196 - val_loss: 0.4385 - val_accuracy: 0.7724\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.3836 - accuracy: 0.8321 - val_loss: 0.4254 - val_accuracy: 0.7798\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.3646 - accuracy: 0.8423 - val_loss: 0.4148 - val_accuracy: 0.7868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5771451350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WT_cTkdhJGu",
        "outputId": "c8f1fea6-74b0-4772-a2d3-7f59bcb2bc97"
      },
      "source": [
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_embeddings = tf.keras.utils.get_file(\"glove.6B.zip\", glove_url, extract = True, cache_dir='.',\n",
        "                                  cache_subdir='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://nlp.stanford.edu/data/glove.6B.zip\n",
            "862183424/862182613 [==============================] - 160s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}