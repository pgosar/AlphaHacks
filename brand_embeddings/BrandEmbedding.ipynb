{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BrandEmbedding",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/c4yVIwSTML/QydnhlKmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgosar/AlphaHacks/blob/main/BrandEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwEHQsLLOW9N"
      },
      "source": [
        "!pip install fire\n",
        "!pip install wikipedia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69xadS_prrQx"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "import wikipedia\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAFOOelOrdW0",
        "outputId": "ff03a515-9472-4d12-ef2a-b039c9dfeda0"
      },
      "source": [
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_embeddings = tf.keras.utils.get_file(\"glove.6B.zip\", glove_url, extract = True, cache_dir='.',\n",
        "                                  cache_subdir='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://nlp.stanford.edu/data/glove.6B.zip\n",
            "862183424/862182613 [==============================] - 162s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTr3cBNTKhC2",
        "outputId": "147a5391-1b40-43b0-c01b-dedddfdf6726"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOyOU4Jx9B5q"
      },
      "source": [
        "GLOVE_PATH = \"/content/glove.6B.200d.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8rcAqokKSLg"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LSqp6Rl88u-"
      },
      "source": [
        "class GloveEmbeddings:\n",
        "    GLOVE_DIR = GLOVE_PATH\n",
        "    EMBEDDING_DIM = 200\n",
        "\n",
        "    @staticmethod\n",
        "    def get_dict_word_embedding(path=GLOVE_DIR, embedding_dim=EMBEDDING_DIM):\n",
        "        f = open(path.format(dim=embedding_dim))\n",
        "\n",
        "        word2emb = dict()\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            word2emb[word] = coefs\n",
        "        f.close()\n",
        "        return word2emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UYcAEHN9wRf"
      },
      "source": [
        "GloveEmbeddings.get_dict_word_embedding()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRId8kBw99lA"
      },
      "source": [
        "IGNORE_WORDS = set(stopwords.words())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpVMDn1LBpnr"
      },
      "source": [
        "_brand_list_fpath = \"/content/data/brand_list2.txt\"\n",
        "DEFAULT_SET_BRANDS = set()\n",
        "with open(_brand_list_fpath) as fp:\n",
        "    for line in fp.readlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        DEFAULT_SET_BRANDS.add(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-L5HmasINKQ"
      },
      "source": [
        "DEFAULT_BRAND_EMB_SAVE_FPATH = 'data/brand_emb.json'\n",
        "ENV_EMBEDDING_GLOVE_6B_FPATH = 'data/glove_embeddings/glove.6B.200d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MggebTiIKMC"
      },
      "source": [
        "DEFAULT_SET_BRANDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHuYQnZSN1U3"
      },
      "source": [
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xso4AuZlPYBw"
      },
      "source": [
        "import fire\n",
        "import json\n",
        "import codecs\n",
        "\n",
        "from string import punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOWXDlNaItYX"
      },
      "source": [
        "def build(set_brands=DEFAULT_SET_BRANDS, fpath_save=DEFAULT_BRAND_EMB_SAVE_FPATH, set_ignore_words=IGNORE_WORDS):\n",
        "  skipped_brands = []\n",
        "  disamb_brands = []\n",
        "\n",
        "  logger.info(\"building knowledge base\")\n",
        "  dict_brand_name_emb = dict()\n",
        "\n",
        "  wrd2emb = GloveEmbeddings.get_dict_word_embedding()\n",
        "\n",
        "  for brand_name in set_brands:\n",
        "    logger.info(\"New loop with {}\".format(brand_name))\n",
        "    #wiki_obj = wikipedia.page(brand_name, auto_suggest=False)\n",
        "\n",
        "    try:\n",
        "      wiki_obj = wikipedia.page(brand_name, auto_suggest=False)\n",
        "    except wikipedia.DisambiguationError as e:\n",
        "      disamb_brands.append(brand_name)\n",
        "      s = random.choice(e.options)\n",
        "      print(\"EXCEPTION TRIGGERED, WITH: \", e.options)\n",
        "      print(\"EXCEPTION TRIGGERED, TRYING WITH: \", s)\n",
        "      wiki_obj = wikipedia.page(s, auto_suggest=False)\n",
        "    except wikipedia.PageError as pe:\n",
        "      skipped_brands.append(brand_name)\n",
        "      print(\"Page error with \", brand_name)\n",
        "      continue\n",
        "\n",
        "    logger.info(\"{brand_name}: {wiki_url}\".format(brand_name=brand_name, wiki_url=wiki_obj.url))\n",
        "    text = wiki_obj.content\n",
        "      \n",
        "    text_tokens = text.split()\n",
        "    list_emb = list()\n",
        "    for token in text_tokens:\n",
        "      token = token.lower()\n",
        "      token = token.strip(punctuation)\n",
        "      if token in set_ignore_words:\n",
        "        #logger.info(\"Token ignored: {}\".format(token))\n",
        "        continue\n",
        "          \n",
        "      emb = wrd2emb.get(token, None)\n",
        "      if emb is not None:\n",
        "        list_emb.append(emb)\n",
        "          \n",
        "    brand_array = np.array(list_emb)\n",
        "    brand_emb = brand_array.mean(axis=0)\n",
        "      \n",
        "    dict_brand_name_emb[brand_name] = brand_emb.tolist()\n",
        "\n",
        "  logger.info(\"saving knowledge base to: `{}`\".format(fpath_save))\n",
        "  with codecs.open(fpath_save, 'w', encoding='utf-8') as fp:\n",
        "    json.dump(dict_brand_name_emb, fp, separators=(',', ':'), indent=4)\n",
        "\n",
        "  logger.info(\"knowledge base compiled\")\n",
        "  print(\"knowledge base compiled\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DQDhxD4Oi2J",
        "outputId": "3ac9d79d-231c-4994-c7cc-222f518393cf"
      },
      "source": [
        "build()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "knowledge base compiled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWUxm4AXHvfZ"
      },
      "source": [
        "#TEST CODE FOR WIKI API\n",
        "\n",
        "for brand_name in set_brands:\n",
        "      logger.info(\"New loop with {}\".format(brand_name))\n",
        "      #wiki_obj = wikipedia.page(brand_name, auto_suggest=False)\n",
        "\n",
        "      try:\n",
        "        wiki_obj = wikipedia.page(brand_name, auto_suggest=False)\n",
        "      except wikipedia.DisambiguationError as e:\n",
        "        try:\n",
        "          s = e.options[0]\n",
        "          print(\"EXCEPTION TRIGGERED, WITH: \", e.options)\n",
        "          print(\"EXCEPTION TRIGGERED, TRYING WITH: \", s)\n",
        "          wiki_obj = wikipedia.page(s, auto_suggest=False)\n",
        "        except wikipedia.DisambiguationError as e:\n",
        "          \n",
        "          continue\n",
        "      except wikipedia.PageError as pe:\n",
        "        print(\"Page error with \", brand_name)\n",
        "        continue\n",
        "\n",
        "        logger.info(\"{brand_name}: {wiki_url}\".format(brand_name=brand_name, wiki_url=wiki_obj.url))\n",
        "        text = wiki_obj.content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHDdtSa-j3y8",
        "outputId": "614e2313-1c53-4d3e-c73f-222f0c561870"
      },
      "source": [
        "os.path.getsize(\"/content/data/brand_emb.json\")/1000000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23748"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "6gNLW3VizQy1",
        "outputId": "dd2246a3-c1ec-4f4e-fb93-39a033a0c4fc"
      },
      "source": [
        "wikipedia.summary(\"501\".encode(\"ascii\", \"ignore\"), auto_suggest = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Year 501 (DI) was a common year starting on Monday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Avienus and Pompeius (or, less frequently, year 1254 Ab urbe condita). The denomination 501 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlknZggDaU4V"
      },
      "source": [
        "import operator\n",
        "def query(target_brand_name, top_n=None, kb_fpath=DEFAULT_BRAND_EMB_SAVE_FPATH, dict_kb=None):\n",
        "\n",
        "    if type(target_brand_name) == str:\n",
        "        target_brand_name = str(target_brand_name)\n",
        "\n",
        "    if dict_kb is None:\n",
        "        with codecs.open(kb_fpath, encoding='utf-8') as fp:\n",
        "            dict_kb = json.load(fp)\n",
        "\n",
        "    target_brand_emb = np.array(dict_kb[target_brand_name])\n",
        "\n",
        "    dict_brand_name_emb_distance = dict()\n",
        "    for candidate_brand_name, candidate_emb in dict_kb.items():\n",
        "\n",
        "        if candidate_brand_name == target_brand_name:\n",
        "            continue\n",
        "\n",
        "        emb_dist = np.linalg.norm(target_brand_emb - np.array(candidate_emb))\n",
        "        dict_brand_name_emb_distance[candidate_brand_name] = emb_dist\n",
        "\n",
        "    sorted_dict = sorted(dict_brand_name_emb_distance.items(), key=operator.itemgetter(1))\n",
        "\n",
        "    if top_n:\n",
        "        sorted_dict = sorted_dict[: top_n]\n",
        "\n",
        "    logger.debug(\"{}: {}\".format(target_brand_name, sorted_dict))\n",
        "\n",
        "    return sorted_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZWprA0UInFS",
        "outputId": "132c156b-4bab-4c3a-f2a7-8f9a90775a3d"
      },
      "source": [
        "query(\"Nestle\", top_n = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"Kellogg's\", 0.6958630893555775),\n",
              " ('The Hershey Company', 0.7453138843880832),\n",
              " ('Amazon Inc', 0.8028214759360586),\n",
              " ('Zara (retailer)', 0.8373109468850889),\n",
              " ('Gap Inc.', 0.8650837031828886)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87zsHy5faWwv"
      },
      "source": [
        "def query_list(list_target_brand_name, top_n=None, kb_fpath=DEFAULT_BRAND_EMB_SAVE_FPATH):\n",
        "\n",
        "    with codecs.open(kb_fpath, encoding='utf-8') as fp:\n",
        "        dict_kb = json.load(fp)\n",
        "\n",
        "    dict_results = dict()\n",
        "    for idx, target_brand_name in enumerate(list_target_brand_name, start=1):\n",
        "        sorted_candidate_brands = query(target_brand_name, top_n=top_n, dict_kb=dict_kb)\n",
        "\n",
        "        dict_results[target_brand_name] = sorted_candidate_brands\n",
        "\n",
        "    return dict_results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}